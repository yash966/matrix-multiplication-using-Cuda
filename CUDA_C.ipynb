{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA_C.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoTw_v7BKFJj"
      },
      "source": [
        "**Machine Learning Assignment 4**\n",
        "\n",
        "Content:\n",
        "\n",
        "1.   Cuda Check\n",
        "2.   Install Plug in to let write and execute cuda code in google colab\n",
        "3.   Cuda Code\n",
        "4.   Cuda Output\n",
        "5.   **Python Codes**\n",
        "\n",
        "    5.a. Python code for *Assignment 3 part 2*\n",
        "\n",
        "    5.b. Python Code for *Assignment 4* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1W2WTJkI1GT"
      },
      "source": [
        "1. Check Cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV5d0gr0amG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24f1fa0d-44a8-4d52-fc9e-6d82043a77e5"
      },
      "source": [
        "\n",
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 25 23:49:00 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaC9mSlwI6rR"
      },
      "source": [
        "2. Install Plug in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03GZgd9XaRlY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a024dd9-badb-4c0d-8aa5-f21a4f204827"
      },
      "source": [
        "\n",
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-7c0sl0pl\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-7c0sl0pl\n",
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb_-CU4KI9PP"
      },
      "source": [
        "3. Cuda Code for Assignment 4 with improvement from the previous code (Assignment 3 Part 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIQcShTzaTNq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b697c5c7-2edd-4b43-e24f-6133933649ad"
      },
      "source": [
        "%%cuda --name matrix_cublas_v2.cu \n",
        "// !nvcc -o /content/src/matrix_cublas_v2 /content/src/matrix_cublas_v2.cu -lcublas -lcurand\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <cublas_v2.h>\n",
        "#include <time.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"curand.h\"\n",
        "\n",
        "\n",
        "#define CUDA_CALL(x) do { if ((x) != cudaSuccess) { \\\n",
        "    printf(\"Error at %s:%d\\n\", __FILE__, __LINE__);\\\n",
        "    return EXIT_FAILURE; }} while(0)\n",
        "\n",
        "\n",
        "cudaError_t checkCuda();\n",
        "\n",
        "\n",
        "/**\n",
        " * Run the matrix multiplication using CUDA cuBlas\n",
        " */\n",
        "int matrixMultiply(dim3& dimsA, dim3& dimsB, int N)\n",
        "{\n",
        "    // Allocate host and device memory for matrices A, B and C\n",
        "    unsigned int size_A = dimsA.x * dimsA.y;\n",
        "    unsigned int mem_size_A = sizeof(float) * size_A;\n",
        "    float* h_A = NULL;\n",
        "    CUDA_CALL(cudaHostAlloc(&h_A, mem_size_A, cudaHostAllocDefault));\n",
        "    float* d_A = NULL;\n",
        "    CUDA_CALL(cudaMalloc(&d_A, mem_size_A));\n",
        "\n",
        "    unsigned int size_B = dimsB.x * dimsB.y;\n",
        "    unsigned int mem_size_B = sizeof(float) * size_B;\n",
        "    float* h_B = NULL;\n",
        "    CUDA_CALL(cudaHostAlloc(&h_B, mem_size_B, cudaHostAllocDefault));\n",
        "    float* d_B = NULL;\n",
        "    CUDA_CALL(cudaMalloc(&d_B, mem_size_B));\n",
        "\n",
        "    dim3 dimsC(dimsB.x, dimsA.y, 1);\n",
        "    unsigned int size_C = dimsC.x * dimsC.y;\n",
        "    unsigned int mem_size_C = sizeof(float) * size_C;\n",
        "    float *h_C = NULL;\n",
        "    CUDA_CALL(cudaHostAlloc(&h_C, mem_size_C, cudaHostAllocDefault));\n",
        "    float *d_C = NULL;\n",
        "    CUDA_CALL(cudaMalloc(&d_C, mem_size_C));\n",
        "\n",
        "    // initiate the random generator on GPU\n",
        "    curandGenerator_t generator;\n",
        "    CUDA_CALL(curandCreateGenerator(&generator, CURAND_RNG_PSEUDO_XORWOW));\n",
        "    CUDA_CALL(curandSetPseudoRandomGeneratorSeed(generator, (int)time(NULL)));\n",
        "\n",
        "    // create cuda stream\n",
        "    const int NUM_STREAMS = 2;\n",
        "    cudaStream_t streams[NUM_STREAMS];\n",
        "    for (int i = 0; i < NUM_STREAMS; ++i)\n",
        "    {\n",
        "        CUDA_CALL(cudaStreamCreate(&streams[i]));\n",
        "    }\n",
        "\n",
        "    // Allocate CUDA events that we'll use for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    CUDA_CALL(cudaEventCreate(&start));\n",
        "    CUDA_CALL(cudaEventCreate(&stop));\n",
        "\n",
        "    // create cublas handle\n",
        "    const float alpha = 1.0f;\n",
        "    const float beta  = 0.0f;\n",
        "    cublasHandle_t handle;\n",
        "    CUDA_CALL(cublasCreate(&handle));\n",
        "\n",
        "    // Starting\n",
        "    CUDA_CALL(cudaEventRecord(start, NULL));\n",
        "    for(int i = 0; i < N; ++i)\n",
        "    {\n",
        "        // Initialising streams\n",
        "        int stream_index = i % NUM_STREAMS;\n",
        "        cudaStream_t stream = streams[stream_index];\n",
        "\n",
        "        // generate device matrixes d_A and d_B directly\n",
        "        CUDA_CALL(curandGenerateUniform(generator, d_A, size_A));\n",
        "        CUDA_CALL(curandGenerateUniform(generator, d_B, size_B));\n",
        "\n",
        "        // caculate matrix C = A * B by using cuBlas\n",
        "        cublasSetStream(handle, stream);\n",
        "        CUDA_CALL(cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, dimsB.x, dimsA.y, dimsA.x, &alpha, \n",
        "            d_B, dimsB.x, d_A, dimsA.x, &beta, d_C, dimsB.x));\n",
        "\n",
        "        // copy result from device to host\n",
        "        CUDA_CALL(cudaMemcpyAsync(h_C, d_C, mem_size_C, cudaMemcpyDeviceToHost, stream));\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < NUM_STREAMS; ++i)\n",
        "    {\n",
        "        CUDA_CALL(cudaStreamSynchronize(streams[i]));\n",
        "    }\n",
        "\n",
        "    // Record the stop event\n",
        "    CUDA_CALL(cudaEventRecord(stop, NULL));\n",
        "    CUDA_CALL(cudaEventSynchronize(stop));\n",
        "\n",
        "    float msec_TotalMatrixMul = 0.0f;\n",
        "    CUDA_CALL(cudaEventElapsedTime(&msec_TotalMatrixMul, start, stop));\n",
        "\n",
        "    // Compute and print the performance\n",
        "    float msec_MatrixMul = msec_TotalMatrixMul / N;\n",
        "    double flops_MatrixMul = 2.0 * (double)dimsA.x * (double)dimsA.y * (double)dimsB.x;\n",
        "    double flopsGiga = (flops_MatrixMul * 1.0e-9f) / (msec_MatrixMul / 1000.0f);\n",
        "    printf(\"Performance= %.2f GFlop/s, AVGTime= %.3f msec, TotalTime=%.3f msc \\n\",\n",
        "        flopsGiga, msec_MatrixMul, msec_TotalMatrixMul);\n",
        " \n",
        "    // Memory Clean up\n",
        "    cudaFreeHost(h_A);\n",
        "    cudaFreeHost(h_B);\n",
        "    cudaFreeHost(h_C);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    for (int i = 0; i < NUM_STREAMS; ++i)\n",
        "    {\n",
        "        CUDA_CALL(cudaStreamDestroy(streams[i]));\n",
        "    }\n",
        "\n",
        "    return EXIT_SUCCESS;\n",
        "} \n",
        "\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    if(checkCuda() != cudaSuccess)\n",
        "    {\n",
        "        return 0;\n",
        "    }\n",
        " \n",
        "    // condition i) A(500*500), B(500*400), N=100\n",
        "    printf(\"Performing condition i: A(500*500), B(500*400), N=100\\n\");\n",
        "    int N1 = 100;\n",
        "    dim3 dimsA1(500, 500, 1);\n",
        "    dim3 dimsB1(400, 500, 1);\n",
        "    matrixMultiply(dimsA1, dimsB1, N1);\n",
        "    printf(\"\\n\");\n",
        " \n",
        "    // condition ii) A(50*20), B(20*50), N=5000\n",
        "    printf(\"Performing condition ii: A(50*20), B(20*50), N=5000\\n\");\n",
        "    int N2 = 5000;\n",
        "    dim3 dimsA2(20, 50, 1);\n",
        "    dim3 dimsB2(50, 20, 1);\n",
        "    matrixMultiply(dimsA2, dimsB2, N2);\n",
        "    printf(\"\\n\");\n",
        " \n",
        "    // condition iii) A(6*4000), B(4000*9), N=1000\n",
        "    printf(\"Performing condition iii: A(6*4000), B(4000*9), N=1000\\n\");\n",
        "    int N3 = 1000;\n",
        "    dim3 dimsA3(4000, 6, 1);\n",
        "    dim3 dimsB3(9, 4000, 1);\n",
        "    matrixMultiply(dimsA3, dimsB3, N3);\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "cudaError_t checkCuda()\n",
        "{\n",
        "    printf(\"Checking CUDA...\\n\");\n",
        "\n",
        "    int devID = 0;\n",
        "    cudaError_t error;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    error = cudaGetDevice(&devID);\n",
        "\n",
        "    if (error != cudaSuccess)\n",
        "    {\n",
        "        printf(\"cudaGetDevice returned error %s (code %d), line(%d)\\n\", cudaGetErrorString(error), error, __LINE__);\n",
        "        return error;\n",
        "    }\n",
        "\n",
        "    error = cudaGetDeviceProperties(&deviceProp, devID);\n",
        "\n",
        "    if (deviceProp.computeMode == cudaComputeModeProhibited)\n",
        "    {\n",
        "        fprintf(stderr, \"Error: device is running in <Compute Mode Prohibited>, no threads can use ::cudaSetDevice().\\n\");\n",
        "        exit(EXIT_SUCCESS);\n",
        "    }\n",
        "\n",
        "    if (error != cudaSuccess)\n",
        "    {\n",
        "        printf(\"cudaGetDeviceProperties returned error %s (code %d), line(%d)\\n\", cudaGetErrorString(error), error, __LINE__);\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        printf(\"GPU Device %d: \\\"%s\\\" with compute capability %d.%d\\n\\n\", devID, deviceProp.name, deviceProp.major, deviceProp.minor);\n",
        "    }\n",
        "\n",
        "    return error;\n",
        "}"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/matrix_cublas_v2.cu'"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VyweDqaaVxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc0054d-52cf-4410-b090-0ca64884d65c"
      },
      "source": [
        "!nvcc -o /content/src/matrix_cublas_v2 /content/src/matrix_cublas_v2.cu -lcublas -lcurand"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[K/content/src/matrix_cublas_v2.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint matrixMultiply(dim3&, dim3&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/src/matrix_cublas_v2.cu:48:87:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between ‘\u001b[01m\u001b[KcurandStatus_t {aka enum curandStatus}\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kenum cudaError\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wenum-compare\u001b[m\u001b[K]\n",
            "     CUDA_CALL(curandCreateGenerator(&generator, CURAND_RNG_PSEUDO_XORWOW));\n",
            "                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/src/matrix_cublas_v2.cu:49:92:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between ‘\u001b[01m\u001b[KcurandStatus_t {aka enum curandStatus}\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kenum cudaError\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wenum-compare\u001b[m\u001b[K]\n",
            "     CUDA_CALL(curandSetPseudoRandomGeneratorSeed(generator, (int)time(NULL)));\n",
            "                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/src/matrix_cublas_v2.cu:68:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between ‘\u001b[01m\u001b[Kenum cublasStatus_t\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kenum cudaError\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wenum-compare\u001b[m\u001b[K]\n",
            "     CUDA_CALL(cublasCreate(&handle));\n",
            "                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/src/matrix_cublas_v2.cu:79:73:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between ‘\u001b[01m\u001b[KcurandStatus_t {aka enum curandStatus}\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kenum cudaError\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wenum-compare\u001b[m\u001b[K]\n",
            "         CUDA_CALL(curandGenerateUniform(generator, d_A, size_A));\n",
            "                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/src/matrix_cublas_v2.cu:80:73:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between ‘\u001b[01m\u001b[KcurandStatus_t {aka enum curandStatus}\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kenum cudaError\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wenum-compare\u001b[m\u001b[K]\n",
            "         CUDA_CALL(curandGenerateUniform(generator, d_B, size_B));\n",
            "                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/src/matrix_cublas_v2.cu:84:160:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between ‘\u001b[01m\u001b[Kenum cublasStatus_t\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kenum cudaError\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wenum-compare\u001b[m\u001b[K]\n",
            "         CUDA_CALL(cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, dimsB.x, dimsA.y, dimsA.x, &alpha,\n",
            "                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRwYnUIEJHdI"
      },
      "source": [
        "4. Cuda Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrGiZvVnaXot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41db43e0-6741-4598-c3b5-0b9e1240a170"
      },
      "source": [
        "!/content/src/matrix_cublas_v2"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking CUDA...\n",
            "GPU Device 0: \"Tesla K80\" with compute capability 3.7\n",
            "\n",
            "Performing condition i: A(500*500), B(500*400), N=100\n",
            "Performance= 344.20 GFlop/s, AVGTime= 0.581 msec, TotalTime=58.105 msc \n",
            "\n",
            "Performing condition ii: A(50*20), B(20*50), N=5000\n",
            "Performance= 1.02 GFlop/s, AVGTime= 0.098 msec, TotalTime=490.836 msc \n",
            "\n",
            "Performing condition iii: A(6*4000), B(4000*9), N=1000\n",
            "Performance= 2.17 GFlop/s, AVGTime= 0.199 msec, TotalTime=198.718 msc \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Rd6MwHJX56"
      },
      "source": [
        "**Python Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F9z4opUJOci"
      },
      "source": [
        "5. a. Python Version for Assignment 3 Part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaPIZCUvJf65"
      },
      "source": [
        "# #Python code for Assignment 3 Part 2\n",
        "\n",
        "# import numpy as np \n",
        "# from timeit import default_timer as timer\n",
        "# import threading\n",
        "\n",
        "# # utilising threads\n",
        "# class cudamatrixthread(threading.Thread):\n",
        "    \n",
        "#     def __init__(self, s_A, B, s_N):\n",
        "#         super(cudamatrixthread, self).__init__()\n",
        "#         self.s_A = s_A\n",
        "#         self.B = B\n",
        "#         self.s_N = s_N\n",
        "\n",
        "#         self.Cs = []\n",
        "\n",
        "#     def run(self) -> None:\n",
        "#         for _ in range(self.s_N):\n",
        "#             s = np.random.rand(self.s_A[0], self.s_A[1])\n",
        "#             d = np.matmul(s, self.B)\n",
        "#             self.Cs.append(d)\n",
        "\n",
        "# # function to perform multiplication\n",
        "# def cuda_multiplication(s_1, s_2, N):\n",
        "#     hight_z, width_z = s_1\n",
        "#     hight_x, width_x = s_2\n",
        "#     B = np.random.rand(hight_x, width_x)\n",
        "    \n",
        "#     tot_thread = 10\n",
        "#     threads = []\n",
        "#     s_N = N // tot_thread\n",
        "#     s_N_last = N % tot_thread\n",
        "    \n",
        "#     start = timer()\n",
        "#     for i in range(tot_thread + 1):\n",
        "#         t_N = s_N\n",
        "#         if s_N_last > 0 and i == tot_thread:\n",
        "#             t_N = s_N_last\n",
        "\n",
        "#         thread = cudamatrixthread(s_1, B, t_N)\n",
        "#         threads.append(thread)\n",
        "#         thread.start()\n",
        "\n",
        "#     # waiting all thread finish\n",
        "#     for thread in threads:\n",
        "#         thread.join()\n",
        "    \n",
        "#     # get result from each thread\n",
        "#     for thread in threads:\n",
        "#         for C in thread.Cs:\n",
        "#             ret_C = C\n",
        "#             # print(C.shape)\n",
        "\n",
        "#     end = timer()\n",
        "\n",
        "#     matricmulti = (end - start) * 1000\n",
        "#     matrix_m = matricmulti / N\n",
        "#     f_matricmul = 2.0 * width_z * hight_z * width_x\n",
        "#     p_gig = (f_matricmul * 1.0e-9) / (matrix_m / 1000.0)\n",
        "#     print(\"Performance= {:.2f} GFlop/s, AVGTime= {:.3f} msec, TotalTime= {:.3f} msc \\n\"\n",
        "#             .format(p_gig, matrix_m, matricmulti))\n",
        "\n",
        "# def main():\n",
        "#     # condition i) A(500*500), B(500*400), N=100\n",
        "#     print(\"Performing condition i: A(500*500), B(500*400), N=100\")\n",
        "#     cuda_multiplication((500, 500), (500, 400), 100)\n",
        "\n",
        "#     # condition ii) A(50*20), B(20*50), N=5000\n",
        "#     print(\"Performing condition ii: A(50*20), B(20*50), N=5000\")\n",
        "#     cuda_multiplication((50, 20), (20, 50), 5000)\n",
        "\n",
        "#     # condition iii) A(6*4000), B(4000*9), N=1000\n",
        "#     print(\"Performing condition iii: A(6*4000), B(4000*9), N=1000\")\n",
        "#     cuda_multiplication((6, 4000), (4000, 9), 1000)\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtQ_RMA0JxFQ"
      },
      "source": [
        "5. b. Python code for assignment 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwegnHwxlA3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8027e8-e2b0-40a5-8929-2123659f456a"
      },
      "source": [
        "#Python code for Assignment 4\n",
        "\n",
        "\n",
        "import numpy as np \n",
        "from timeit import default_timer as timer\n",
        "import threading\n",
        "\n",
        "\n",
        "class cudamatrixthread(threading.Thread):\n",
        "    \n",
        "    def __init__(self, s_A, s_B, s_N):\n",
        "        super(cudamatrixthread, self).__init__()\n",
        "        self.s_A = s_A\n",
        "        self.s_B = s_B\n",
        "        self.s_N = s_N\n",
        "\n",
        "        self.Cs = []\n",
        "\n",
        "    def run(self) -> None:\n",
        "        for _ in range(self.s_N):\n",
        "            x = np.random.rand(self.s_A[0], self.s_A[1])\n",
        "            c = np.random.rand(self.s_B[0], self.s_B[1])\n",
        "            z = np.matmul(x, c)\n",
        "            self.Cs.append(z)\n",
        "\n",
        "\n",
        "def cuda_multiplication(s_1, s_2, N):\n",
        "    hight_z, width_z = s_1\n",
        "    hight_x, width_x = s_2\n",
        "    B = np.random.rand(hight_x, width_x)\n",
        "    \n",
        "    tot_thread = 10\n",
        "    threads = []\n",
        "    s_N = N // tot_thread\n",
        "    s_N_last = N % tot_thread\n",
        "    \n",
        "    start = timer()\n",
        "    for i in range(tot_thread + 1):\n",
        "        t_N = s_N\n",
        "        if s_N_last > 0 and i == tot_thread:\n",
        "            t_N = s_N_last\n",
        "\n",
        "        thread = cudamatrixthread(s_1, s_2, t_N)\n",
        "        threads.append(thread)\n",
        "        thread.start()\n",
        "\n",
        "    # waiting all thread finish\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "    \n",
        "    # get result from each thread\n",
        "    for thread in threads:\n",
        "        for C in thread.Cs:\n",
        "            ret_C = C\n",
        "            # print(C.shape)\n",
        "\n",
        "    end = timer()\n",
        "\n",
        "    matricmulti = (end - start) * 1000\n",
        "    matrix_m = matricmulti / N\n",
        "    f_matricmul = 2.0 * width_z * hight_z * width_x\n",
        "    p_gig = (f_matricmul * 1.0e-9) / (matrix_m / 1000.0)\n",
        "    print(\"Performance= {:.2f} GFlop/s, AVGTime= {:.3f} msec, TotalTime= {:.3f} msc \\n\"\n",
        "            .format(p_gig, matrix_m, matricmulti))\n",
        "\n",
        "def main():\n",
        "    # condition i) A(500*500), B(500*400), N=100\n",
        "    print(\"Performing condition i: A(500*500), B(500*400), N=100\")\n",
        "    cuda_multiplication((500, 500), (500, 400), 100)\n",
        "\n",
        "    # condition ii) A(50*20), B(20*50), N=5000\n",
        "    print(\"Performing condition ii: A(50*20), B(20*50), N=5000\")\n",
        "    cuda_multiplication((50, 20), (20, 50), 5000)\n",
        "\n",
        "    # condition iii) A(6*4000), B(4000*9), N=1000\n",
        "    print(\"Performing condition iii: A(6*4000), B(4000*9), N=1000\")\n",
        "    cuda_multiplication((6, 4000), (4000, 9), 1000)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing condition i: A(500*500), B(500*400), N=100\n",
            "Performance= 13.07 GFlop/s, AVGTime= 15.304 msec, TotalTime= 1530.447 msc \n",
            "\n",
            "Performing condition ii: A(50*20), B(20*50), N=5000\n",
            "Performance= 1.03 GFlop/s, AVGTime= 0.097 msec, TotalTime= 486.003 msc \n",
            "\n",
            "Performing condition iii: A(6*4000), B(4000*9), N=1000\n",
            "Performance= 0.49 GFlop/s, AVGTime= 0.890 msec, TotalTime= 890.124 msc \n",
            "\n"
          ]
        }
      ]
    }
  ]
}